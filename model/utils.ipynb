{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: John N. PouguÃ©-Biyong, jpougue@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da685f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from pathlib import Path\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34efa962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBuilder:\n",
    "  \n",
    "    def __init__(self, \n",
    "                 edge_data, \n",
    "                 dataset_name='BirdwatchSG', \n",
    "                 save_folds=False, \n",
    "                 use_topics=True): \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            edge_data pd.DataFrame: edge data (source_idx, target_idx, topic, weight)\n",
    "            dataset_name str: BirdwatchSG or TwitterSG, or your own dataset name\n",
    "            save_folds bool: set to False if CVfolds for dataset_name (& use_topics settings) \n",
    "                             are already cached, True otherwise\n",
    "            use_topics bool: set to False if edge-attribute information should be ignored\n",
    "        \"\"\"\n",
    "        self.dataset_name = dataset_name \n",
    "        self.save_folds = save_folds\n",
    "        use_topics = use_topics\n",
    "        if use_topics:\n",
    "            assert 'topic' in list(edge_data)\n",
    "            self.topic_data_available = True\n",
    "        else:\n",
    "            self.topic_data_available = False\n",
    "            \n",
    "        paths = ['../datasets/cache/{}/CVfolds'.format(dataset_name),\n",
    "                 '../datasets/cache/{}/walks'.format(dataset_name),  \n",
    "                 '../datasets/cache/{}/contexts'.format(dataset_name)]\n",
    "        for path in paths:\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "        \n",
    "        self.__mapping(edge_data)\n",
    "        if self.save_folds:\n",
    "            self.__info()\n",
    "        self.__create_subsamples()\n",
    "\n",
    "    def __mapping(self, df):\n",
    "        \"\"\" \n",
    "        Maps nodes to arbitrary indexes.\n",
    "        Input:\n",
    "            df pd.DataFrame: edge data\n",
    "        \"\"\"\n",
    "        if self.save_folds:\n",
    "            print('Mapping instances to idx...')\n",
    "            self.node2idx = {}\n",
    "            self.idx2node = {}\n",
    "            idx = 0\n",
    "            nodes = list(df.source_idx.unique()) + list(df.target_idx.unique())\n",
    "            nodes = sorted(list(set(nodes)))\n",
    "            for node in nodes:\n",
    "                self.node2idx[node] = idx\n",
    "                self.idx2node[idx] = node\n",
    "                idx += 1\n",
    "            df['source_idx'] = df['source_idx'].apply(lambda x: self.node2idx[x])\n",
    "            df['target_idx'] = df['target_idx'].apply(lambda x: self.node2idx[x])\n",
    "            if self.topic_data_available:\n",
    "                self.topic2idx = {}\n",
    "                self.idx2topic = {}\n",
    "                idx = 0\n",
    "                topics = sorted(list(df.topic.unique()))\n",
    "                for topic in topics:\n",
    "                    self.topic2idx[topic] = idx\n",
    "                    self.idx2topic[idx] = topic\n",
    "                    idx += 1\n",
    "                df['topic_idx'] = df['topic'].apply(lambda x: self.topic2idx[x])\n",
    "            else:\n",
    "                self.topic2idx = {'unk': 0}\n",
    "                self.idx2topic = {0: 'unk'}\n",
    "                df['topic'] = 'unk'\n",
    "                df['topic_idx'] = 0\n",
    "            edges = df \\\n",
    "            .groupby(['source_idx', 'target_idx', 'topic_idx']) \\\n",
    "            .agg({'rating': 'sum'}) \\\n",
    "            .reset_index()\n",
    "            edges = edges[edges.rating != 0]\n",
    "            edges['weight'] = edges['rating'].apply(lambda x: 1 if x > 0 else -1)\n",
    "            self.edge_data = edges\n",
    "            self.size_graph = len(self.node2idx)\n",
    "            print('Mapped instances.')\n",
    "        \n",
    "            keys = [key for key in self.node2idx]\n",
    "            values = [self.node2idx[key] for key in self.node2idx]\n",
    "            dataframe = pd.DataFrame({'node': keys, 'node_idx': values})\n",
    "            dataframe.to_csv('../datasets/cache/{}/node_mapping.csv'.format(self.dataset_name), \n",
    "                             index=False)\n",
    "        \n",
    "            keys = [key for key in self.topic2idx]\n",
    "            values = [self.topic2idx[key] for key in self.topic2idx]\n",
    "            dataframe = pd.DataFrame({'topic': keys, 'topic_idx': values})\n",
    "            dataframe.to_csv('../datasets/cache/{}/topic_mapping.csv'.format(self.dataset_name), \n",
    "                             index=False)\n",
    "  \n",
    "    def __info(self):\n",
    "        print('--- graph----')\n",
    "        print('#nodes:', len(self.node2idx))\n",
    "        print('#edges:', len(self.edge_data))\n",
    "        print('%edges+:', \n",
    "              str(round(len(self.edge_data[self.edge_data.weight == 1]) * 100 \\\n",
    "                  / len(self.edge_data))) + '%')\n",
    "        if self.topic_data_available:\n",
    "            print('#topics:', len(self.topic2idx))\n",
    "        else:\n",
    "            print('No topic used.')\n",
    "          \n",
    "    def __create_subsamples(self):\n",
    "        \"\"\" \n",
    "        Creates 5-CV folds.\n",
    "        \"\"\" \n",
    "        if self.save_folds:\n",
    "            self.training_data = {}\n",
    "            self.test_data = {}\n",
    "            print('Creating 5-CV folds...')\n",
    "            X = self.edge_data[['source_idx', 'target_idx', 'topic_idx']].to_numpy()\n",
    "            y = self.edge_data[['weight']].to_numpy()\n",
    "            skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "            count = 1\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                X_train, y_train = X[train_index], y[train_index]\n",
    "                df_train = pd.DataFrame(X_train, \n",
    "                                        columns = ['source_idx','target_idx', 'topic_idx'])\n",
    "                training_nodes = set(list(df_train.source_idx.unique()) \\\n",
    "                              + list(df_train.target_idx.unique())\n",
    "                              )\n",
    "                training_topics = set(list(df_train.topic_idx.unique()))\n",
    "                X_test_unfiltered, y_test_unfiltered = X[test_index], y[test_index]\n",
    "                df_test = pd.DataFrame(X_test_unfiltered, \n",
    "                                     columns = ['source_idx','target_idx','topic_idx'])\n",
    "                df_test['ID'] = list(range(len(df_test)))\n",
    "                df_test = df_test[(df_test.source_idx.isin(training_nodes)) \\\n",
    "                                & (df_test.target_idx.isin(training_nodes)) \\\n",
    "                                & (df_test.topic_idx.isin(training_topics))]\n",
    "                X_test = X_test_unfiltered[list(df_test.ID), :]\n",
    "                y_test = y_test_unfiltered[list(df_test.ID), :]\n",
    "                self.training_data[count] = pd.DataFrame(X_train, \n",
    "                                                         columns = ['source_idx','target_idx','topic_idx'])\n",
    "                self.training_data[count]['weight'] = y_train\n",
    "                self.training_data[count].to_csv('../datasets/cache/{dataset}/CVfolds/train_{c}.csv' \\\n",
    "                        .format(dataset=self.dataset_name, c=count), index=False)\n",
    "                self.test_data[count] = pd.DataFrame(X_test, \n",
    "                                                     columns = ['source_idx','target_idx','topic_idx'])\n",
    "                self.test_data[count]['weight'] = y_test\n",
    "                self.test_data[count].to_csv('../datasets/cache/{dataset}/CVfolds/test_{c}.csv' \\\n",
    "                        .format(dataset=self.dataset_name, c=count), index=False)\n",
    "                count += 1\n",
    "            print('Created 5-CV folds.')\n",
    "        else:\n",
    "            self.training_data = {}\n",
    "            self.test_data = {}\n",
    "            for count in range(5):\n",
    "                self.training_data[count + 1] = \\\n",
    "                    pd.read_csv('../datasets/cache/{dataset}/CVfolds/train_{c}.csv' \\\n",
    "                        .format(dataset=self.dataset_name, c=count+1), index_col=False)\n",
    "                self.test_data[count + 1] = \\\n",
    "                    pd.read_csv('../datasets/cache/{dataset}/CVfolds/test_{c}.csv' \\\n",
    "                        .format(dataset=self.dataset_name, c=count+1), index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "  \n",
    "    def __init__(self, dataset_name='BirdwatchSG'):\n",
    "        self.dataset_name = dataset_name \n",
    "      \n",
    "        print('Collecting mappings...')\n",
    "        node_path = '../datasets/cache/{}/node_mapping.csv'.format(self.dataset_name)\n",
    "        self.node_mapping = pd.read_csv(node_path, index_col=False)\n",
    "        topic_path = '../datasets/cache/{}/topic_mapping.csv'.format(self.dataset_name)\n",
    "        self.topic_mapping = pd.read_csv(topic_path, index_col=False)\n",
    "        print('Collected mapping.')\n",
    "      \n",
    "        print('Creating mapping dicts...')\n",
    "        self.idx2node = {item.node_idx: item.node for _, item in self.node_mapping.iterrows()}\n",
    "        self.node2idx = {item.node: item.node_idx for _, item in self.node_mapping.iterrows()}\n",
    "        self.idx2topic = {item.topic_idx: item.topic for _, item in self.topic_mapping.iterrows()}\n",
    "        self.topic2idx = {item.topic: item.topic_idx for _, item in self.topic_mapping.iterrows()}\n",
    "        print('Created mapping dicts.')\n",
    "      \n",
    "        self.size_graph = len(self.node2idx)\n",
    "        self.training_data = {}\n",
    "        self.test_data = {}\n",
    "      \n",
    "        print('\\nCollecting CVfolds...')\n",
    "        for count in range(5):\n",
    "            path = '../datasets/cache/{dataset}/CVfolds/train_{c}.csv'.format(dataset=self.dataset_name, c=count+1)\n",
    "            self.training_data[count + 1] = pd.read_csv(path, index_col=False)\n",
    "          \n",
    "            path = '../datasets/cache/{dataset}/CVfolds/test_{c}.csv'.format(dataset=self.dataset_name, c=count+1)\n",
    "            self.test_data[count + 1] = pd.read_csv(path, index_col=False)\n",
    "\n",
    "        print('Collected CVfolds.\\n')\n",
    "      \n",
    "        if len(set(self.training_data[1].topic_idx.tolist())) > 1:\n",
    "            self.topic_data_available = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
